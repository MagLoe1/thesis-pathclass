{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script creates csv files for to compare and evaluate the directly predicted morphology codes against the merged histology and behavior codes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from eval_helper_functions import load_df, get_mor_his_beh_scores, get_task_path_dict, get_pred_label_files_MT, get_pred_label_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# input dir\n",
    "result_collection = os.path.join(\"..\", \"model_output\")\n",
    "print(os.path.exists(result_collection))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dir\n",
    "store_results_dir = os.path.join(\".\", f\"{date.today()}_mor_his_beh_eval\")\n",
    "if not os.path.exists(store_results_dir):\n",
    "    os.mkdir(store_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"mor\", \"his\", \"beh\"]\n",
    "mt_tasks = [\"morsit\", \"behhissit\"]\n",
    "\n",
    "model_types = [\"LOGR\", \n",
    "               \"CNN\", \"MTCNN\",\n",
    "               \"HISAN\", \"MTHISAN\",\n",
    "               \"BERT\", \"MTBERT\"]\n",
    "model_sorter = {\"LOGR\": \"a\",\n",
    "                \"CNN\" : \"b\",\n",
    "                \"MTCNN\": \"c\",\n",
    "                \"HISAN\": \"d\",\n",
    "                \"MTHISAN\": \"e\",\n",
    "                \"BERT\": \"f\",\n",
    "                \"MTBERT\": \"g\"}\n",
    "# note: KB-BERT was abbreviated to BERT in the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating evaluation for model LOGR, (cws True)\n",
      "Number of classes (combined histology+behavior) [25, 24, 25, 23, 26]\n",
      "Creating evaluation for model LOGR, (cws False)\n",
      "Number of classes (combined histology+behavior) [20, 18, 20, 20, 19]\n",
      "Creating evaluation for model CNN, (cws True)\n",
      "Number of classes (combined histology+behavior) [32, 29, 30, 33, 31]\n",
      "Creating evaluation for model CNN, (cws False)\n",
      "Number of classes (combined histology+behavior) [24, 26, 25, 24, 24]\n",
      "Creating evaluation for model MTCNN, (cws True)\n",
      "Number of classes (combined histology+behavior) [27, 26, 28, 28, 27]\n",
      "Creating evaluation for model MTCNN, (cws False)\n",
      "Number of classes (combined histology+behavior) [20, 25, 21, 23, 21]\n",
      "Creating evaluation for model HISAN, (cws True)\n",
      "Number of classes (combined histology+behavior) [31, 28, 29, 33, 32]\n",
      "Creating evaluation for model HISAN, (cws False)\n",
      "Number of classes (combined histology+behavior) [30, 27, 25, 28, 28]\n",
      "Creating evaluation for model MTHISAN, (cws True)\n",
      "Number of classes (combined histology+behavior) [29, 27, 26, 27, 27]\n",
      "Creating evaluation for model MTHISAN, (cws False)\n",
      "Number of classes (combined histology+behavior) [21, 23, 22, 23, 24]\n",
      "Creating evaluation for model BERT, (cws True)\n",
      "Number of classes (combined histology+behavior) [32, 30, 29, 31, 30]\n",
      "Creating evaluation for model BERT, (cws False)\n",
      "Number of classes (combined histology+behavior) [28, 28, 25, 26, 28]\n",
      "Creating evaluation for model MTBERT, (cws True)\n",
      "Number of classes (combined histology+behavior) [26, 25, 25, 27, 27]\n",
      "Creating evaluation for model MTBERT, (cws False)\n",
      "Number of classes (combined histology+behavior) [22, 23, 21, 22, 20]\n"
     ]
    }
   ],
   "source": [
    "pred_true_labels_filename = \"pred_true_labels\"\n",
    "\n",
    "\n",
    "model_summary = pd.DataFrame(columns=[\"acc_mor\",\"acc_hisbeh\", \n",
    "                                      \"acc_his_from_mor\", \"acc_his\", \n",
    "                                      \"acc_beh_from_mor\", \"acc_beh\",\n",
    "                                      \"f1_mor\", \"f1_hisbeh\",  \n",
    "                                      \"f1_his_from_mor\",  \"f1_his\",  \n",
    "                                      \"f1_beh_from_mor\",  \"f1_beh\"])\n",
    "\n",
    "model_summary_excl_other = pd.DataFrame(columns=[\"acc_mor\",\"acc_hisbeh\", \n",
    "                                                 \"acc_his_from_mor\", \"acc_his\", \n",
    "                                                 \"acc_beh_from_mor\", \"acc_beh\",\n",
    "                                                 \"f1_mor\", \"f1_hisbeh\",  \n",
    "                                                 \"f1_his_from_mor\",  \"f1_his\",  \n",
    "                                                 \"f1_beh_from_mor\",  \"f1_beh\"])\n",
    "\n",
    "for model_type in model_types:\n",
    "    for cw_flag in [True, False]:\n",
    "        unique_labels_pred_his_beh_excl_other = []\n",
    "        unique_labels_pred_mor_excl_other = []\n",
    "        if \"MT\" not in model_type:\n",
    "\n",
    "            task_dict = get_task_path_dict(result_collection, model_type=model_type, tasks=tasks)\n",
    "            pred_true_label_files = get_pred_label_files(task_path_dict=task_dict,\n",
    "                                                    pred_true_labels_filename=f\"{pred_true_labels_filename}.csv\",\n",
    "                                                    cw_flag=cw_flag)\n",
    "        else:\n",
    "            task_dict = get_task_path_dict(result_collection, model_type=model_type, tasks=mt_tasks)\n",
    "            pred_true_label_files = get_pred_label_files_MT(task_path_dict=task_dict,\n",
    "                                                            pred_true_labels_filename=f\"{pred_true_labels_filename}.csv\",\n",
    "                                                            cw_flag=cw_flag)\n",
    "        \n",
    "        print(f\"Creating evaluation for model {model_type}, (cws {cw_flag})\")\n",
    "\n",
    "        all_folds_scores = dict()\n",
    "        all_folds_scores_excl_other = dict()\n",
    "        for fold in range(1, 6):\n",
    "\n",
    "            mor_df = load_df(pred_true_label_files[\"mor\"][str(fold)])\n",
    "            his_df = load_df(pred_true_label_files[\"his\"][str(fold)])\n",
    "            beh_df = load_df(pred_true_label_files[\"beh\"][str(fold)])\n",
    "            \n",
    "\n",
    "            combo_df = pd.DataFrame({\"true_mor\" : mor_df[\"labels_true_alph\"],\n",
    "                                    \"true_his\" : his_df[\"labels_true_alph\"],\n",
    "                                    \"true_beh\" : beh_df[\"labels_true_alph\"],\n",
    "\n",
    "                                    \"true_hisbeh\": his_df[\"labels_true_alph\"] + beh_df[\"labels_true_alph\"],\n",
    "\n",
    "                                    \"pred_mor\" : mor_df[\"labels_pred_alph\"],\n",
    "                                    \"pred_his\" : his_df[\"labels_pred_alph\"],\n",
    "                                    \"pred_beh\": beh_df[\"labels_pred_alph\"],\n",
    "                                    \"pred_hisbeh\" : his_df[\"labels_pred_alph\"] + beh_df[\"labels_pred_alph\"]},\n",
    "                                    )\n",
    "            \n",
    "\n",
    "            \n",
    "            assert list(combo_df[\"true_mor\"]) == list(combo_df[\"true_hisbeh\"])\n",
    "\n",
    "            combo_df[\"pred_his_from_mor\"] = [val[:-1] for val in mor_df[\"labels_pred_alph\"].values]\n",
    "            combo_df[\"pred_beh_from_mor\"] = [val[-1] for val in mor_df[\"labels_pred_alph\"].values]\n",
    "            \n",
    "            all_folds_scores[fold] = get_mor_his_beh_scores(combo_df, excl_other=False)\n",
    "\n",
    "            # include only reports that do not belong to other class\n",
    "            combo_excl_other = combo_df.copy(deep=True)\n",
    "            combo_excl_other = combo_excl_other[combo_excl_other[\"true_mor\"] != \"99999\"]\n",
    "            assert len(combo_excl_other) < len(combo_df)\n",
    "\n",
    "            assert \"99999\" not in combo_excl_other[\"true_mor\"].unique()\n",
    "            assert \"9999\" not in combo_excl_other[\"true_his\"].unique()\n",
    "            assert \"9\" not in combo_excl_other[\"true_beh\"].unique()\n",
    "\n",
    "            unique_labels_pred_his_beh_excl_other.append(len(combo_excl_other[\"pred_hisbeh\"].unique()))\n",
    "            unique_labels_pred_mor_excl_other.append(len(combo_excl_other[\"pred_mor\"].unique()))\n",
    "            all_folds_scores_excl_other[fold] = get_mor_his_beh_scores(combo_excl_other, excl_other=True)\n",
    "\n",
    "\n",
    "        # create dfs and add mean\n",
    "        all_folds_scores_df = pd.DataFrame.from_dict(all_folds_scores, orient=\"index\")\n",
    "        mean = all_folds_scores_df.mean()\n",
    "        std = all_folds_scores_df.std()\n",
    "        all_folds_scores_df.loc[\"mean\"] = mean\n",
    "        all_folds_scores_df.loc[\"std\"] = std\n",
    "\n",
    "\n",
    "        all_folds_scores_excl_other_df = pd.DataFrame.from_dict(all_folds_scores_excl_other, orient=\"index\")\n",
    "        mean_no = all_folds_scores_excl_other_df.mean()\n",
    "        std_no = all_folds_scores_excl_other_df.std()\n",
    "        all_folds_scores_excl_other_df.loc[\"mean\"] = mean_no\n",
    "        all_folds_scores_excl_other_df.loc[\"std\"] = std_no\n",
    "        \n",
    "        \n",
    "        # save as csv files\n",
    "        if cw_flag:\n",
    "            cw_suffix = \"_CW_\"\n",
    "        else:\n",
    "            cw_suffix = \"\"\n",
    "\n",
    "        all_folds_scores_df.to_csv(os.path.join(store_results_dir, f\"{model_type}{cw_suffix[:-1]}_eval_with_other.csv\"), encoding=\"utf-8\")\n",
    "        all_folds_scores_excl_other_df.to_csv(os.path.join(store_results_dir, f\"{model_type}{cw_suffix[:-1]}_eval_excl_other.csv\"), encoding=\"utf-8\")\n",
    "\n",
    "        model_summary.loc[f\"{cw_suffix[1:]}{model_sorter[model_type]}_{model_type}\"] = all_folds_scores_df.loc[\"mean\"]\n",
    "        model_summary_excl_other.loc[f\"{cw_suffix[1:]}{model_sorter[model_type]}_{model_type}_excl_other\"] = all_folds_scores_excl_other_df.loc[\"mean\"]\n",
    "        print(\"Number of classes (combined histology+behavior)\", unique_labels_pred_his_beh_excl_other)\n",
    "\n",
    "model_summary.sort_index(inplace=True)\n",
    "model_summary.to_csv(os.path.join(store_results_dir, f\"SUMMARY_mor_his_beh_means_with_other.csv\"), encoding=\"utf-8\")\n",
    "\n",
    "model_summary_excl_other.sort_index(inplace=True)\n",
    "model_summary_excl_other.to_csv(os.path.join(store_results_dir, f\"SUMMARY_mor_his_beh_means_excl_other.csv\"), encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_in_order = model_sorter.keys()\n",
    "for result_df, suffix in [(model_summary, \"with_other\"), \n",
    "                          (model_summary_excl_other, \"excl_other\")]:\n",
    "    \n",
    "    # save with rounded numbers\n",
    "    result_df = result_df * 100\n",
    "    result_df = result_df.round(decimals=2)\n",
    "    result_df.to_csv(os.path.join(store_results_dir, f\"SUMMARY_ROUNDED_mor_his_beh_means_{suffix}.csv\"), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "\n",
    "    results_with_CW = result_df.iloc[:7, :].copy(deep=True)\n",
    "    results_without_CW = result_df.iloc[7:, :].copy(deep=True)\n",
    "    assert len(results_with_CW) == len(results_without_CW)\n",
    "\n",
    "    # assign new index to concat dataframes neatly later on\n",
    "    for i, modelname in enumerate(models_in_order):\n",
    "        assert modelname in results_with_CW.index[i]\n",
    "        assert modelname in results_without_CW.index[i]\n",
    "    results_with_CW.index = models_in_order\n",
    "    results_without_CW.index = models_in_order\n",
    "\n",
    "    # change column names to keep info about cws\n",
    "    for col in results_with_CW.columns:\n",
    "        results_with_CW.rename({col: col+\"_+CW\"}, inplace=True, axis=\"columns\")\n",
    "\n",
    "    for col in results_without_CW.columns:\n",
    "        results_without_CW.rename({col: col+\"_-CW\"}, inplace=True, axis=\"columns\")\n",
    "\n",
    "    table_order = [\"acc_mor_+CW\",\"acc_hisbeh_+CW\",\n",
    "                    \"acc_mor_-CW\",\"acc_hisbeh_-CW\",\n",
    "                    \"f1_mor_+CW\", \"f1_hisbeh_+CW\",\n",
    "                    \"f1_mor_-CW\", \"f1_hisbeh_-CW\", \n",
    "                    \n",
    "                    \"acc_his_from_mor_+CW\", \"acc_his_+CW\", \n",
    "                    \"acc_his_from_mor_-CW\", \"acc_his_-CW\",\n",
    "                    \"f1_his_from_mor_+CW\",  \"f1_his_+CW\",  \n",
    "                    \"f1_his_from_mor_-CW\",  \"f1_his_-CW\", \n",
    "\n",
    "                    \"acc_beh_from_mor_+CW\", \"acc_beh_+CW\",\n",
    "                    \"acc_beh_from_mor_-CW\", \"acc_beh_-CW\",\n",
    "                    \"f1_beh_from_mor_+CW\",  \"f1_beh_+CW\",\n",
    "                    \"f1_beh_from_mor_-CW\",  \"f1_beh_-CW\"]\n",
    "\n",
    "    table_df = pd.concat([results_with_CW, results_without_CW], axis=1)\n",
    "    table_df_final_order = table_df[table_order]\n",
    "\n",
    "    table_df_final_order.to_csv(os.path.join(store_results_dir, f\"SUMMARY_ROUNDED_TABLE_mor_his_beh_means_{suffix}.csv\"), encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
